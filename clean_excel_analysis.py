#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ANÃLISE LIMPA DA PLANILHA GLÃš-GARANTIAS
Abordagem step-by-step com DataFrame para validaÃ§Ã£o precisa
"""

import pandas as pd
import numpy as np
from datetime import datetime
import sys

def analyze_excel_clean(file_path):
    print("=" * 70)
    print("ANALISE LIMPA - PLANILHA GLU-GARANTIAS")
    print("=" * 70)
    
    try:
        # 1. LEITURA BRUTA DA PLANILHA
        print("\nPASSO 1: LENDO PLANILHA COMPLETA...")
        
        # Ler todas as abas primeiro
        excel_file = pd.ExcelFile(file_path)
        print(f"   Abas encontradas: {excel_file.sheet_names}")
        
        # Ler aba 'Tabela'
        if 'Tabela' not in excel_file.sheet_names:
            print("ERRO: Aba 'Tabela' nao encontrada!")
            return
        
        df_raw = pd.read_excel(file_path, sheet_name='Tabela')
        print(f"   Dimensoes originais: {df_raw.shape[0]} linhas x {df_raw.shape[1]} colunas")
        print(f"   Colunas: {list(df_raw.columns)}")
        
        # 2. IDENTIFICAR COLUNAS NECESSÃRIAS
        print("\nPASSO 2: MAPEANDO COLUNAS NECESSARIAS...")
        
        required_columns = {
            'NOrdem_OSv': 'order_number',
            'Data_OSv': 'order_date', 
            'Fabricante_Mot': 'engine_manufacturer',
            'Descricao_Mot': 'engine_description',
            'ModeloVei_Osv': 'vehicle_model',
            'ObsCorpo_OSv': 'raw_defect_description',
            'RazaoSocial_Cli': 'responsible_mechanic',
            'TotalProd_OSv': 'parts_total',
            'TotalServ_OSv': 'labor_total', 
            'Total_OSv': 'grand_total',
            'Status_OSv': 'order_status'
        }
        
        # Verificar quais colunas existem
        missing_cols = []
        existing_cols = {}
        
        for req_col, mapped_name in required_columns.items():
            if req_col in df_raw.columns:
                existing_cols[req_col] = mapped_name
                print(f"   âœ… {req_col} -> {mapped_name}")
            else:
                missing_cols.append(req_col)
                print(f"   âŒ {req_col} -> NÃƒO ENCONTRADA")
        
        if missing_cols:
            print(f"\nâš ï¸  Colunas obrigatÃ³rias faltando: {missing_cols}")
            return
        
        # 3. SELECIONAR APENAS COLUNAS NECESSÃRIAS
        print(f"\nğŸ“‹ PASSO 3: SELECIONANDO APENAS COLUNAS NECESSÃRIAS...")
        df_selected = df_raw[list(existing_cols.keys())].copy()
        df_selected.columns = list(existing_cols.values())
        
        print(f"   DataFrame reduzido: {df_selected.shape[0]} linhas x {df_selected.shape[1]} colunas")
        
        # 4. ANÃLISE INICIAL DOS DADOS
        print(f"\nğŸ” PASSO 4: ANÃLISE INICIAL DOS DADOS...")
        
        print(f"   Linhas com dados (nÃ£o todas NaN): {df_selected.dropna(how='all').shape[0]}")
        print(f"   Valores Ãºnicos por coluna:")
        
        for col in df_selected.columns:
            non_null = df_selected[col].notna().sum()
            unique_vals = df_selected[col].nunique()
            print(f"     {col}: {non_null} valores ({unique_vals} Ãºnicos)")
        
        # 5. LIMPEZA BÃSICA
        print(f"\nğŸ§¹ PASSO 5: LIMPEZA BÃSICA...")
        
        # Remover linhas completamente vazias
        df_clean = df_selected.dropna(how='all').copy()
        print(f"   ApÃ³s remover linhas vazias: {df_clean.shape[0]} linhas")
        
        # 6. ANÃLISE DE CAMPOS OBRIGATÃ“RIOS
        print(f"\nâœ… PASSO 6: VERIFICANDO CAMPOS OBRIGATÃ“RIOS...")
        
        mandatory_fields = ['order_number', 'order_date', 'order_status']
        
        for field in mandatory_fields:
            null_count = df_clean[field].isna().sum()
            print(f"   {field}: {null_count} valores nulos")
        
        # Filtrar apenas registros com campos obrigatÃ³rios preenchidos
        df_mandatory = df_clean.dropna(subset=mandatory_fields).copy()
        print(f"   ApÃ³s filtro de campos obrigatÃ³rios: {df_mandatory.shape[0]} linhas")
        
        # 7. ANÃLISE DE STATUS
        print(f"\nğŸ“Š PASSO 7: ANÃLISE DE STATUS...")
        
        status_counts = df_mandatory['order_status'].value_counts()
        print("   DistribuiÃ§Ã£o de status:")
        for status, count in status_counts.items():
            print(f"     '{status}': {count} registros")
        
        # Filtrar apenas status vÃ¡lidos (G, GO, GU)
        valid_statuses = ['G', 'GO', 'GU']
        df_status_valid = df_mandatory[df_mandatory['order_status'].isin(valid_statuses)].copy()
        print(f"   ApÃ³s filtro de status vÃ¡lidos (G/GO/GU): {df_status_valid.shape[0]} linhas")
        
        # 8. ANÃLISE DE DATAS
        print(f"\nğŸ“… PASSO 8: ANÃLISE DE DATAS...")
        
        # Tentar converter datas
        df_dates = df_status_valid.copy()
        
        # FunÃ§Ã£o para tentar converter diferentes formatos de data
        def convert_date_flexible(date_val):
            if pd.isna(date_val):
                return None
            
            # Se jÃ¡ Ã© datetime
            if isinstance(date_val, datetime):
                return date_val
            
            # Se Ã© nÃºmero (serial Excel)
            if isinstance(date_val, (int, float)):
                try:
                    # FÃ³rmula Excel para Python
                    return pd.Timestamp('1900-01-01') + pd.Timedelta(days=date_val-2)
                except:
                    return None
            
            # Se Ã© string
            if isinstance(date_val, str):
                try:
                    return pd.to_datetime(date_val)
                except:
                    return None
            
            return None
        
        print("   Convertendo formatos de data...")
        df_dates['order_date_converted'] = df_dates['order_date'].apply(convert_date_flexible)
        
        # Remover datas que nÃ£o puderam ser convertidas
        df_dates_valid = df_dates.dropna(subset=['order_date_converted']).copy()
        print(f"   ApÃ³s conversÃ£o de datas: {df_dates_valid.shape[0]} linhas")
        
        # AnÃ¡lise das datas convertidas
        if len(df_dates_valid) > 0:
            min_date = df_dates_valid['order_date_converted'].min()
            max_date = df_dates_valid['order_date_converted'].max()
            print(f"   Range de datas: {min_date.strftime('%Y-%m-%d')} a {max_date.strftime('%Y-%m-%d')}")
            
            # DistribuiÃ§Ã£o por ano
            df_dates_valid['year'] = df_dates_valid['order_date_converted'].dt.year
            year_counts = df_dates_valid['year'].value_counts().sort_index()
            print("   DistribuiÃ§Ã£o por ano:")
            for year, count in year_counts.items():
                print(f"     {year}: {count} registros")
        
        # 9. FILTRO DE DATA >= 2019
        print(f"\nğŸ¯ PASSO 9: APLICANDO FILTRO DE DATA >= 2019...")
        
        df_final = df_dates_valid[df_dates_valid['order_date_converted'].dt.year >= 2019].copy()
        print(f"   ApÃ³s filtro >= 2019: {df_final.shape[0]} linhas")
        
        # 10. RESULTADO FINAL
        print(f"\n" + "=" * 70)
        print(f"ğŸ“‹ RESULTADO FINAL")
        print(f"=" * 70)
        print(f"âœ… Total de registros vÃ¡lidos: {len(df_final)}")
        
        if len(df_final) > 0:
            print(f"ğŸ“Š DistribuiÃ§Ã£o por status:")
            final_status = df_final['order_status'].value_counts()
            for status, count in final_status.items():
                percentage = (count / len(df_final)) * 100
                print(f"   {status}: {count} registros ({percentage:.1f}%)")
            
            print(f"ğŸ“… DistribuiÃ§Ã£o por ano:")
            final_years = df_final['year'].value_counts().sort_index()
            for year, count in final_years.items():
                percentage = (count / len(df_final)) * 100
                print(f"   {year}: {count} registros ({percentage:.1f}%)")
            
            print(f"ğŸ“ˆ Range final: {df_final['order_date_converted'].min().strftime('%Y-%m-%d')} a {df_final['order_date_converted'].max().strftime('%Y-%m-%d')}")
        
        print(f"=" * 70)
        
        return df_final
        
    except Exception as e:
        print(f"âŒ ERRO: {str(e)}")
        import traceback
        traceback.print_exc()
        return None

if __name__ == "__main__":
    file_path = "GLÃº-Garantias.xlsx"
    result = analyze_excel_clean(file_path)